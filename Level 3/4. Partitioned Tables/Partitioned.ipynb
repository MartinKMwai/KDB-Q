{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autorun": true,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#;.pykx.disableJupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autorun": true,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyKX now running in 'jupyter_qfirst' mode. All cells by default will be run as q code. \n",
      "Include '%%py' at the beginning of each cell to run as python code. \n"
     ]
    }
   ],
   "source": [
    "# https://code.kx.com/pykx/3.0/examples/jupyter-integration.html#q-first-mode\n",
    "import pykx as kx\n",
    "kx.util.jupyter_qfirst_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database present - loading local partitioned database /home/jovyan/course-advanced/.hidden/db/taq\n"
     ]
    }
   ],
   "source": [
    "system\"l init.q\"\n",
    "\n",
    "//subsequent calls to this init will throw an error because we have changed directory \n",
    "    //this error can be safely ignored \n",
    "\n",
    "//if you need to do a hard reset, please restart the kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning outcomes** \n",
    "\n",
    "To understand:\n",
    "* The structure of a partitioned database\n",
    "* How to modify a partitioned database\n",
    "* Considerations when working with extremely large tables \n",
    "* On disk compression\n",
    "* Introduction to dbmaint.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "As implied by the name, a partitioned database is structured as a series of partitions, each of which contains folders for each table in the database. These folders are really splayed tables which store the data related to that particular partition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the duration of this module we will work with data that has been created in the `/db/taq` folder local to this module directory. This data has already been loaded into the current notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`daily`depth`mas`nbbo`quote`trade\n"
     ]
    }
   ],
   "source": [
    "tables[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`2020.01.02`2020.01.03`2020.01.06`2020.01.07`2020.01.08`2020.01.09`2020.01.10`2020.01.13`2020.01.14`2020.01.15`2020.01.16`2020.01.17`2020.01.20`2020.01.21`2020.01.22`2020.01.23`2020.01.24`2020.0..\n"
     ]
    }
   ],
   "source": [
    "key `:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.01.02 2020.01.03 2020.01.06 2020.01.07 2020.01.08 2020.01.09 2020.01.10 2020.01.13 2020.01.14 2020.01.15 2020.01.16 2020.01.17 2020.01.20 2020.01.21 2020.01.22 2020.01.23 2020.01.24 2020.01.27..\n"
     ]
    }
   ],
   "source": [
    "//.Q.pt\n",
    "//.Q.pf\n",
    ".Q.pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `daily`,`depth` and `mas` files are flat tables, while `nbbo`, `quote` and `trade` are partitioned tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Structure of a partitioned database.\n",
    "\n",
    "The Partitions of a partitioned database are special directories that contain tables split by a certain criteria e.g. date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " <img src=\"../images/PartitionedDb.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## On Disk structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Inside each partition are the tables, which will each have their own directories with the structure of a splayed table. Splayed tables can be thought of as tables being cut vertically along columns, while partitioned tables likewise cut vertically along columns (splayed) and then cut horizontally along either date, month, year, or int. \n",
    " \n",
    "The reason for splitting these tables is usually due to the large amounts of volumes associated with a given split - e.g. daily for highly frequent high volume data.\n",
    " \n",
    "Partitioned tables are suitable for tables with millions of records per partition (e.g. daily time series data) and queries usually are executed against a limited set of partitions, so that only those partitions specified are accessed/queried. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Partition types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tables can only be [partitioned](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#143-partitioned-tables) on the following types: \n",
    "* date \n",
    "* month \n",
    "* year \n",
    "* long (previously int in versions pre v3.x) \n",
    "\n",
    "The partition type is determined from the partition name format; \n",
    " \n",
    "    2008.06.10 – the type is date, \n",
    "    2008.06 – the type is month, \n",
    "    2008 - the type is year, \n",
    "    25 - the type is long. \n",
    " \n",
    "One database can contain only one partition type at a time. Each table in a partition will have an extra virtual column with the same type and name as the partition type, and same value as the partition name.\n",
    "\n",
    "\n",
    "For example, if we have trade table partitioned on date, each day's trade data will have a virtual column called date, and the value will be the name of the partition (folder) the data is from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c    | t f a\n",
      "-----| -----\n",
      "date | d    \n",
      "sym  | s   p\n",
      "time | t    \n",
      "price| f    \n",
      "size | j    \n",
      "stop | b    \n",
      "cond | c    \n",
      "ex   | c    \n"
     ]
    }
   ],
   "source": [
    "meta trade                //our trade table shows a column called date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`.d`cond`ex`price`size`stop`sym`time\n"
     ]
    }
   ],
   "source": [
    "key `:2020.01.02/trade    //no file for the date column exists - inferred from directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating a Partitioned Database \n",
    "\n",
    "Creating a partitioned database involves the creation of many separate schema consistent splayed tables, divided into different directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First we'll mock up some data to save: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.01 c      55.33425\n",
      "2020.01.01 k      15.73327\n",
      "2020.01.01 c      9.554756\n",
      "2020.01.01 n      63.89734\n",
      "2020.01.01 g      46.26324\n"
     ]
    }
   ],
   "source": [
    "n: 10000\n",
    "show 5 sublist t:([]date: asc n?2020.01.01 + til 10; sensor:n?`1;reading:n?82.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have data from 10 different days so if we create a date partitioned database, we will have ten different partitions. We can save our data into a directory `.../sensorDB` beside our `taq` database and given our data contains symbol columns, we need to enumerate before attempting to save down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`2020.01.02`sym\n",
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.01 c      55.33425\n",
      "2020.01.01 k      15.73327\n",
      "2020.01.01 c      9.554756\n",
      "2020.01.01 n      63.89734\n",
      "2020.01.01 g      46.26324\n",
      "2020.01.01 i      28.48091\n",
      "2020.01.01 b      6.236588\n",
      "2020.01.01 k      18.03259\n",
      "2020.01.01 b      26.43753\n",
      "2020.01.01 d      71.13844\n",
      "2020.01.01 g      49.22499\n",
      "2020.01.01 h      79.25316\n",
      "2020.01.01 d      2.35304 \n",
      "2020.01.01 g      63.77775\n",
      "2020.01.01 j      40.07898\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show enumT:.Q.en[`:../sensorDB;t]\n",
    "key `:../sensorDB                 //this has created the folder and our sym file - check via Jupyter Home!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.01 c      55.33425\n",
      "2020.01.01 k      15.73327\n",
      "2020.01.01 c      9.554756\n",
      "2020.01.01 n      63.89734\n",
      "2020.01.01 g      46.26324\n",
      "2020.01.01 i      28.48091\n",
      "2020.01.01 b      6.236588\n",
      "2020.01.01 k      18.03259\n",
      "2020.01.01 b      26.43753\n",
      "2020.01.01 d      71.13844\n",
      "2020.01.01 g      49.22499\n",
      "2020.01.01 h      79.25316\n",
      "2020.01.01 d      2.35304 \n",
      "2020.01.01 g      63.77775\n",
      "2020.01.01 j      40.07898\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "//meta t\n",
    "enumT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The final step is now to save our data down into a separate directory for each date - we begin with getting our list of dates, and writing to disk for one of the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#2020.01.01 2020.01.02 2020.01.03 2020.01.04 2020.01.05 2020.01.06 2020.01.07 2020.01.08 2020.01.09 2020.01.10\n",
      "2020.01.01\n"
     ]
    }
   ],
   "source": [
    "show dts:exec distinct date from enumT \n",
    "show dt: first dts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020.01.01\n",
      ":../sensorDB/2020.01.01/sensorTab/\n",
      "`:../sensorDB/2020.01.01/sensorTab/\n"
     ]
    }
   ],
   "source": [
    "`$(string dt)\n",
    "/,`sensorTab`\n",
    "show path: ` sv `:../sensorDB,(`$string dt),`sensorTab`\n",
    "path set select from enumT where date = 2020.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Taking a moment to look at the directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2020.01.01  2020.01.02\\tsym\"\n"
     ]
    }
   ],
   "source": [
    "system\"dir ../sensorDB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's load this data in, and see how it looks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.02 l      46.68199\n",
      "2020.01.02 o      70.27368\n",
      "2020.01.02 l      37.28489\n",
      "2020.01.02 n      32.30919\n",
      "2020.01.02 m      81.84824\n",
      "2020.01.02 f      73.51871\n",
      "2020.01.02 h      50.66184\n",
      "2020.01.02 j      65.68112\n",
      "2020.01.02 d      18.3917 \n",
      "2020.01.02 n      76.96679\n",
      "2020.01.02 b      76.42116\n",
      "2020.01.02 o      15.94944\n",
      "2020.01.02 k      59.70587\n",
      "2020.01.02 c      60.60719\n",
      "2020.01.02 c      55.50768\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "\\l ../sensorDB\n",
    "select from sensorTab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hmmm something looks a bit odd - can you spot what has happened and where we've gone wrong?\n",
    "\n",
    "<b>*Take some time to review the steps up to here before continuing on!*</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.02 l      46.68199\n",
      "2020.01.02 o      70.27368\n",
      "2020.01.02 l      37.28489\n",
      "2020.01.02 n      32.30919\n",
      "2020.01.02 m      81.84824\n",
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.02 k      10.66391\n",
      "2020.01.02 m      77.11459\n",
      "2020.01.02 i      72.0592 \n",
      "2020.01.02 n      50.15432\n",
      "2020.01.02 p      47.86468\n"
     ]
    }
   ],
   "source": [
    "5#select from sensorTab where date = 2020.01.01\n",
    "5#select from sensorTab where date = 2020.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are two errors here: \n",
    "1. We saved the data from our table relating to 2020.01.02 but saved this data under our 2020.01.01 partition!\n",
    "2. We saved down a column with the same name as our date partition! \n",
    "\n",
    "Well done if you spotted either (or both!)\n",
    "\n",
    "Fundamentally the query structure with kdb+/q partitioned tables relies on leveraging the top level on disk partition structure to reduce the amount of data drawn back. If you recall, the `where` clause is executed first in qSQL. \n",
    "\n",
    "This means that when we specify `where date = 2020.01.01` that is the partition in which we look, and then because we had stored down (incorrectly) a column with the same name as our partition, this is returned from the retrieval, giving us the odd looking results we see above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i> We should never store a table column on disk with the same name as our partitions! </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "reveal": "ryzhg76fxed",
    "reveal-hidden": false
   },
   "source": [
    "##### Exercise\n",
    "\n",
    "Fix the error above by saving the data in the correct directory instead and reloading the database. \n",
    "\n",
    "Verify this now returns sensible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "reveal": "ryzhg76fxed"
   },
   "outputs": [],
   "source": [
    "//\\pwd\n",
    "//\\mv 2020.01.01 2020.01.02\n",
    "\\l . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "reveal": "ryzhg76fxed"
   },
   "outputs": [],
   "source": [
    "select from sensorTab where date = 2020.01.01\n",
    "select from sensorTab where date = 2020.01.02   //success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/home/jovyan/course-advanced/.hidden/db/sensorDB\"\n",
      "()\n"
     ]
    },
    {
     "ename": "QError",
     "evalue": "./2020.01.02/2020.01.01/.d. OS reports: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQError\u001b[0m                                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//your answer here \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpwd\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmv 2020.01.01 2020.01.02\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43ml . \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pykx/nbextension.py:181\u001b[0m, in \u001b[0;36mq\u001b[0;34m(instructions, code)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell contents not saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m due to error during execution/saving.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(_q), kx\u001b[38;5;241m.\u001b[39mQConnection):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pykx/nbextension.py:169\u001b[0m, in \u001b[0;36mq\u001b[0;34m(instructions, code)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mor\u001b[39;00m kx\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpykx_qdebug:\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mprint\u001b[39m(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m kx\u001b[38;5;241m.\u001b[39mQError(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpy()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     display(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m displayRet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mQError\u001b[0m: ./2020.01.02/2020.01.01/.d. OS reports: No such file or directory"
     ]
    }
   ],
   "source": [
    "//your answer here \n",
    "\\pwd\n",
    "\\mv 2020.01.01 2020.01.02\n",
    "\\l . \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date sensor reading\n",
      "-------------------\n",
      "                   \n",
      "                   \n",
      "                   \n",
      "                   \n",
      "                   \n",
      "date       sensor reading \n",
      "--------------------------\n",
      "2020.01.02 k      10.66391\n",
      "2020.01.02 m      77.11459\n",
      "2020.01.02 i      72.0592 \n",
      "2020.01.02 n      50.15432\n",
      "2020.01.02 p      47.86468\n"
     ]
    }
   ],
   "source": [
    "5#select from sensorTab where date = 2020.01.01\n",
    "5#select from sensorTab where date = 2020.01.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "reveal": "iqp538h2ndc",
    "reveal-hidden": false
   },
   "source": [
    "Continue with the exercise and create a function - `saveTableParted` which will take the following arguments: \n",
    "* p: partition directory home \n",
    "* t: a table to save \n",
    "* tableName : name to call the new table\n",
    "\n",
    "And creates a date partitioned database - the table has a date column, but ensure this is not saved down.\n",
    "\n",
    "Check this works by running the following successfully: \n",
    "    \n",
    "    saveTableParted[`:.;t;`sensorTab] \n",
    "    \n",
    "And loading in the completed database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "reveal": "iqp538h2ndc"
   },
   "outputs": [],
   "source": [
    "saveTableParted:{[d;t;tableName] \n",
    "            dts: exec distinct date from t;              //get the unique dates in the table - will be our partitions\n",
    "            enumT: .Q.en[d;t];                           //enumerating against our directory to save to - NB!\n",
    "            {[d;tab;tableName;dt]                        //need to loop over all dates, so making a lambda \n",
    "                toSave: select from tab where date = dt;   //only want to save data for this date\n",
    "                path: ` sv d,(`$string dt),tableName,`;    //file path for our new data directory  (NB needs ending /)\n",
    "                path set toSave                            //saving using set\n",
    "                        }[d;enumT;tableName] each dts    //everything else is the same, looping over dates\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "reveal": "iqp538h2ndc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:./2020.01.01/sensorTab/`:./2020.01.02/sensorTab/`:./2020.01.03/sensorTab/`:./2020.01.04/sensorTab/`:./2020.01.05/sensorTab/`:./2020.01.06/sensorTab/`:./2020.01.07/sensorTab/`:./2020.01.08/sensorT..\n"
     ]
    }
   ],
   "source": [
    "saveTableParted[`:.;t;`sensorTab] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "reveal": "iqp538h2ndc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x   \n",
      "----------| ----\n",
      "2020.01.01| 959 \n",
      "2020.01.02| 962 \n",
      "2020.01.03| 1021\n",
      "2020.01.04| 1008\n",
      "2020.01.05| 1021\n",
      "2020.01.06| 1001\n",
      "2020.01.07| 1018\n",
      "2020.01.08| 1034\n",
      "2020.01.09| 984 \n",
      "2020.01.10| 992 \n",
      "date      | x   \n",
      "----------| ----\n",
      "2020.01.01| 959 \n",
      "2020.01.02| 962 \n",
      "2020.01.03| 1021\n",
      "2020.01.04| 1008\n",
      "2020.01.05| 1021\n",
      "2020.01.06| 1001\n",
      "2020.01.07| 1018\n",
      "2020.01.08| 1034\n",
      "2020.01.09| 984 \n",
      "2020.01.10| 992 \n",
      "1b\n"
     ]
    }
   ],
   "source": [
    "\\l . \n",
    "select count i by date from sensorTab\n",
    "select count i by date from t                    \n",
    "t~ update value sensor from select from sensorTab     //removing the enumeration to verify these match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "saveTableParted:{[d;t;tableName] \n",
    "            dts: exec distinct date from t;              //get the unique dates in the table - will be our partitions\n",
    "            enumT: .Q.en[d;t];                           //enumerating against our directory to save to - NB!\n",
    "            {[d;tab;tableName;dt]                        //need to loop over all dates, so making a lambda \n",
    "                toSave: select from tab where date = dt;   //only want to save data for this date\n",
    "                path: ` sv d,(`$string dt),tableName,`;    //file path for our new data directory  (NB needs ending /)\n",
    "                path set toSave                            //saving using set\n",
    "                        }[d;enumT;tableName] each dts    //everything else is the same, looping over dates\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Before moving on please move back into the /db/taq directory by running the below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.02| 146790\n",
      "2020.01.03| 152463\n",
      "2020.01.06| 147258\n",
      "2020.01.07| 141046\n",
      "2020.01.08| 144751\n",
      "2020.01.09| 140281\n",
      "2020.01.10| 137972\n",
      "2020.01.13| 147727\n",
      "2020.01.14| 145750\n",
      "2020.01.15| 146362\n",
      "2020.01.16| 150264\n",
      "2020.01.17| 149713\n",
      "2020.01.20| 147049\n",
      "2020.01.21| 144268\n",
      "2020.01.22| 146677\n",
      "..\n",
      "\"/home/jovyan/course-advanced/.hidden/db/taq\"\n"
     ]
    }
   ],
   "source": [
    "\\l ../taq\n",
    "select count i by date from trade\n",
    "\\pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Querying data in a Partitioned Database \n",
    "\n",
    "We will see querying data in a partitioned database is very similar to querying data in a splayed table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:12px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i>  When querying a partitioned database, it is important to include the partition as the first constraint in the <code>where</code> clause. This speeds up queries, as kdb+/q only has to search through the specified partitions, as opposed to all of them.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Restrictions \n",
    "Similar to the behaviour we saw with Splayed tables, we cannot `update`, `delete` or `exec` data directly from a partitioned table - we must first return the data into memory to use these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:30:00.021 09:30:00.025 09:30:00.028 09:30:00.031 09:30:00.041 09:30:00.147 09:30:00.216 09:30:00.413 09:30:00.439 09:30:00.441 09:30:00.536 09:30:00.575 09:30:00.594 09:30:00.646 09:30:00.796 09..\n"
     ]
    }
   ],
   "source": [
    "exec time from \n",
    "    select from trade where date = last date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Upon initial load of the database, the partitioned structure is memory mapped - running count i by date across the entire `trade` table, or returning the count of any tables is usually not an expensive operation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.02| 146790\n",
      "2020.01.03| 152463\n",
      "2020.01.06| 147258\n",
      "2020.01.07| 141046\n",
      "2020.01.08| 144751\n",
      "2020.01.09| 140281\n",
      "2020.01.10| 137972\n",
      "2020.01.13| 147727\n",
      "2020.01.14| 145750\n",
      "2020.01.15| 146362\n",
      "2020.01.16| 150264\n",
      "2020.01.17| 149713\n",
      "2020.01.20| 147049\n",
      "2020.01.21| 144268\n",
      "2020.01.22| 146677\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "select count i by date from trade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "However, outside of this we should always ensure that our database queries have a constraint against the partition column.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Partitioned Database Utilities\n",
    "There are a number of kdb+/q [`.Q utilities`](https://code.kx.com/q/ref/dotq/) which are helpful when working with large partitioned databases, some of the more popular are discussed here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `.Q.chk`\n",
    "\n",
    "[`.Q.chk`](https://code.kx.com/q/ref/dotq/#qchk-fill-hdb) is a utility which will look across all partitions in the data and fill any missing tables with an empty schema definition (as per the schema in the most recent partition), allowing the data to be loadable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's work through an example of saving down just one individual table in a new directory:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sym  time         price size stop cond ex\n",
      "-----------------------------------------\n",
      "AAPL 09:30:00.021 83.88 17   0    G    N \n",
      "AAPL 09:30:00.025 83.87 74   0    J    N \n",
      "AAPL 09:30:00.028 83.84 57   0    N    N \n",
      "AAPL 09:30:00.031 83.87 81   0    K    N \n",
      "AAPL 09:30:00.041 83.87 52   0    G    N \n",
      "AAPL 09:30:00.147 83.83 20   0    Z    N \n",
      "AAPL 09:30:00.216 83.98 67   0    8    N \n",
      "AAPL 09:30:00.413 83.97 47   0    P    N \n",
      "AAPL 09:30:00.439 83.95 70   0    8    N \n",
      "AAPL 09:30:00.441 83.9  62   0    A    N \n",
      "AAPL 09:30:00.536 83.94 18   0    G    N \n",
      "AAPL 09:30:00.575 83.89 32   0    G    N \n",
      "AAPL 09:30:00.594 83.85 72   0    A    N \n",
      "AAPL 09:30:00.646 83.76 10   0    O    N \n",
      "AAPL 09:30:00.796 83.77 25   0    P    N \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show t: get `:2020.01.02/trade   //grabbing a convenient table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:2025.03.07/trade/\n",
      ":2025.03.07/trade/\n"
     ]
    }
   ],
   "source": [
    "show fp:` sv hsym[`$string .z.d],`trade`   //our filepath to save to \n",
    "fp set t                                   //t is already enumerated - we were lazy before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can reload our database and inspect our data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2025.03.07| 146790\n",
      "2020.01.31| 150960\n",
      "2020.01.30| 152930\n",
      "2020.01.29| 158067\n",
      "2020.01.28| 162477\n",
      "2020.01.27| 155718\n",
      "2020.01.24| 153839\n",
      "2020.01.23| 145783\n",
      "2020.01.22| 146677\n",
      "2020.01.21| 144268\n",
      "2020.01.20| 147049\n",
      "2020.01.17| 149713\n",
      "2020.01.16| 150264\n",
      "2020.01.15| 146362\n",
      "2020.01.14| 145750\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "\\l . \n",
    "`date xdesc select count i by date from trade   //our new data is there - all good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/home/jovyan/course-advanced/.hidden/db/taq\"\n"
     ]
    }
   ],
   "source": [
    "\\pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Great! It looks like we were successful in adding our data and can query our `trade` table - but what about our other tables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "`date xdesc select count i by date from quote   //no such table!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is problematic - we have broken our `quote` table by adding `trade` without supplying data for `quote` in the same partiton. Luckily this is where we can use `.Q.chk`, which takes as an input the directory of the database we want to unify: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "..\n"
     ]
    }
   ],
   "source": [
    ".Q.chk[`:.]    //it returns a list of the directories to which is added data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.31| 750931\n",
      "2020.01.30| 761369\n",
      "2020.01.29| 788241\n",
      "2020.01.28| 813131\n",
      "2020.01.27| 780007\n",
      "2020.01.24| 769034\n",
      "2020.01.23| 728081\n",
      "2020.01.22| 733703\n",
      "2020.01.21| 722632\n",
      "2020.01.20| 734560\n",
      "2020.01.17| 750446\n",
      "2020.01.16| 753248\n",
      "2020.01.15| 732749\n",
      "2020.01.14| 729196\n",
      "2020.01.13| 737660\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "`date xdesc select count i by date from quote   //problem solved! We don't have an entry for our date as it's empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a very commonly used utility when working with databases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `.Q.view`\n",
    "One of the most helpful for protecting database from inexperienced users is the [`.Q.view`](https://code.kx.com/q/ref/dotq/#qview-subview) utility - this allows us to specify a default window against which non constrained database queries are executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.02| 146790\n",
      "2020.01.03| 152463\n",
      "2020.01.06| 147258\n",
      "2020.01.07| 141046\n",
      "2020.01.08| 144751\n",
      "2020.01.09| 140281\n",
      "2020.01.10| 137972\n",
      "2020.01.13| 147727\n",
      "2020.01.14| 145750\n",
      "2020.01.15| 146362\n",
      "2020.01.16| 150264\n",
      "2020.01.17| 149713\n",
      "2020.01.20| 147049\n",
      "2020.01.21| 144268\n",
      "2020.01.22| 146677\n",
      "..\n",
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.02| 146790\n",
      "2020.01.03| 152463\n",
      "2020.01.06| 147258\n",
      "2020.01.07| 141046\n",
      "2020.01.08| 144751\n"
     ]
    }
   ],
   "source": [
    "select count i by date from trade                                  //query against the full database \n",
    "select count i by date from trade where date in (5 sublist date)   //query against the first 5 dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`.Q.view` allows us to set a subview on our partitioned tables that gets enacted when people query without a constraint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    ".Q.view 5 sublist date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.02| 146790\n",
      "2020.01.03| 152463\n",
      "2020.01.06| 147258\n",
      "2020.01.07| 141046\n",
      "2020.01.08| 144751\n"
     ]
    }
   ],
   "source": [
    "select count i by date from trade   //no constraint explicitly defined but subset to the date provided to .Q.view "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This can be removed by calling `.Q.view` with no input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.02| 146790\n",
      "2020.01.03| 152463\n",
      "2020.01.06| 147258\n",
      "2020.01.07| 141046\n",
      "2020.01.08| 144751\n",
      "2020.01.09| 140281\n",
      "2020.01.10| 137972\n",
      "2020.01.13| 147727\n",
      "2020.01.14| 145750\n",
      "2020.01.15| 146362\n",
      "2020.01.16| 150264\n",
      "2020.01.17| 149713\n",
      "2020.01.20| 147049\n",
      "2020.01.21| 144268\n",
      "2020.01.22| 146677\n",
      "..\n",
      "date      | x     \n",
      "----------| ------\n",
      "2020.01.28| 162477\n",
      "2020.01.29| 158067\n",
      "2020.01.30| 152930\n",
      "2020.01.31| 150960\n",
      "2025.03.07| 146790\n"
     ]
    }
   ],
   "source": [
    ".Q.view[]\n",
    "select count i by date from trade\n",
    ".Q.view -5 sublist date \n",
    "select count i by date from trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is helpful as a fail-safe to protect against unconstrained queries which may cause the process to attempt to read the whole table into memory, consuming all the RAM and causing the process to fail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `.Q.dpft`\n",
    "Arguably the most frequently used utility associated with partitioned databases, [`.Q.dpft`](https://code.kx.com/q/ref/dotq/#qdpft-save-table) allows the saving down of a global table to a specified directory and is the end of day save down utility leveraged in vanilla tick.q architecture setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's breakdown the syntax: \n",
    "\n",
    "    .Q.dpft[d;p;f;t] [.Q.(directory)(partition)(field - parted)(table - global)]\n",
    "where `d` is a directory handle, `p` is a partition of a database sorted (`p#`) on `f` a field of the table named by\n",
    "`t`, a table handle (symbol). \n",
    "\n",
    "Grabbing some data, let's use this to save down: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sym  time         price size stop cond ex\n",
      "-----------------------------------------\n",
      "AAPL 09:30:00.021 83.88 17   0    G    N \n",
      "AAPL 09:30:00.025 83.87 74   0    J    N \n",
      "AAPL 09:30:00.028 83.84 57   0    N    N \n",
      "AAPL 09:30:00.031 83.87 81   0    K    N \n",
      "AAPL 09:30:00.041 83.87 52   0    G    N \n",
      "AAPL 09:30:00.147 83.83 20   0    Z    N \n",
      "AAPL 09:30:00.216 83.98 67   0    8    N \n",
      "AAPL 09:30:00.413 83.97 47   0    P    N \n",
      "AAPL 09:30:00.439 83.95 70   0    8    N \n",
      "AAPL 09:30:00.441 83.9  62   0    A    N \n",
      "AAPL 09:30:00.536 83.94 18   0    G    N \n",
      "AAPL 09:30:00.575 83.89 32   0    G    N \n",
      "AAPL 09:30:00.594 83.85 72   0    A    N \n",
      "AAPL 09:30:00.646 83.76 10   0    O    N \n",
      "AAPL 09:30:00.796 83.77 25   0    P    N \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show t: get `:2020.01.02/trade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n"
     ]
    }
   ],
   "source": [
    ".Q.dpft[`:.;.z.d;`sym;`t]       //this will save the table t to the partitioned database \n",
    "\\l . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`nbbo`quote`t`trade\n"
     ]
    }
   ],
   "source": [
    "key hsym[`$ string .z.d]        //we can see this table is now present in our most recent directory! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i> .Q.dpft has it's limitations like .Q.en in that we can only name the enumerated file `sym`. If we wanted to change the enumerated file, we can use <a href=\"https://code.kx.com/q/ref/dotq/#qdpfts-save-table-with-symtable\">.Q.dpfts</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newtab\n"
     ]
    }
   ],
   "source": [
    "newtab:([]sym:10?`AAPL`MSFT`KX;price:10?100.) //creating another table\n",
    ".Q.dpfts[`:newhdb;.z.d;`sym;`newtab;`mysym] //saving to new directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Other useful utility functions to know  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most of the time, the partitioned database is stored on a server in which users can't access to see what the structure it has. There are many questions that we need answered to structure our queries can be as performant. How do we know if a table is a flat file or partitioned ? How do we find out how the database is partitioned ? Luckily kdb+/q has functions that will tell us this information:\n",
    "\n",
    "* [.Q.pt](https://code.kx.com/q/ref/dotq/#qpt-partitioned-tables)- returns a list of partitioned tables\n",
    "* [.Q.pf](https://code.kx.com/q/ref/dotq/#qpf-partition-field)- returns the partitioned field\n",
    "* [.Q.pv](https://code.kx.com/q/ref/dotq/#qpv-modified-partition-values)- returns the partitions values \n",
    "* [.Q.cn](https://code.kx.com/q/ref/dotq/#qcn-count-partitioned-table)- returns the count of the partitioned table\n",
    "* [.Q.pd](https://code.kx.com/q/ref/dotq/#qpd-modified-partition-locations)- returns the location of the partitions\n",
    "* [.Q.pn](https://code.kx.com/q/ref/dotq/#qpn-partition-counts)- returns the number of rows in each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbbo | \n",
      "quote| \n",
      "t    | \n",
      "trade| \n"
     ]
    }
   ],
   "source": [
    ".Q.pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`nbbo`quote`t`trade\n",
      "date\n",
      "2020.01.02 2020.01.03 2020.01.06 2020.01.07 2020.01.08 2020.01.09 2020.01.10 2020.01.13 2020.01.14 2020.01.15 2020.01.16 2020.01.17 2020.01.20 2020.01.21 2020.01.22 2020.01.23 2020.01.24 2020.01.27..\n",
      "`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.`:.\n",
      "146790 152463 147258 141046 144751 140281 137972 147727 145750 146362 150264 149713 147049 144268 146677 145783 153839 155718 162477 158067 152930 150960 146790\n",
      "nbbo | ()\n",
      "quote| ()\n",
      "t    | ()\n",
      "trade| 146790 152463 147258 141046 144751 140281 137972 147727 145750 146362 150264 149713 147049 144268 146677 145783 153839 155718 162477 158067 152930 150960 146790\n",
      "731943 759571 735464 707893 724462 702548 689443 737660 729196 732749 753248 750446 734560 722632 733703 728081 769034 780007 813131 788241 761369 750931 0\n",
      "nbbo | ()\n",
      "quote| 731943 759571 735464 707893 724462 702548 689443 737660 729196 732749 753248 750446 734560 722632 733703 728081 769034 780007 813131 788241 761369 750931 0\n",
      "t    | ()\n",
      "trade| 146790 152463 147258 141046 144751 140281 137972 147727 145750 146362 150264 149713 147049 144268 146677 145783 153839 155718 162477 158067 152930 150960 146790\n"
     ]
    }
   ],
   "source": [
    ".Q.pt\n",
    ".Q.pf\n",
    ".Q.pv \n",
    ".Q.pd\n",
    ".Q.cn trade\n",
    ".Q.pn  //nbbo,quote and t are empty because .Q.cn was only executed for trade\n",
    ".Q.cn quote\n",
    ".Q.pn //quote number is filled in now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modifying a Partitioned Database\n",
    "If we want to modify a table in our partitioned database we need to modifying each of the underlying splayed tables that exist within each partition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The [dbmaint.q](https://github.com/KxSystems/kdb/blob/master/utils/dbmaint.md) script provides some useful utilities for editing and maintaining a historical database (HDB). Generally, these functions are safer and should be used in place of the raw commands for any database amendments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "system \"l .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i>Once you have modified the on-disk database, remember to adjust the schema (tick/???.q) to reflect your changes to the data.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the dbMaint functions, the following arguments apply:\n",
    "\n",
    "* **dbdir** : a file symbol for the database folder\n",
    "* **table** : the symbol naming a table\n",
    "* **col** : the symbol name of a column\n",
    "\n",
    "The dbMaint script has already been loaded into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i> The <a href=\"https://github.com/KxSystems/kdb/blob/master/utils/dbmaint.md\"><b>dbmaint.q</b></a> script is a valuable tool in our arsenal when it comes to modifying databases! </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Modify Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For simplicity of understanding we will looks at two of these functions:\n",
    "* addcol - Adds a new column to table with value default value in each row.\n",
    "* deletecol - Deletes a column from table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i> Other common use cases of  <a href=\"https://github.com/KxSystems/kdb/blob/master/utils/dbmaint.md\"><b>dbmaint.q</b></a> script include renaming columns or table name, reordering columns, adding or removing attributes and casting columns.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Firstly let's look at how we would add a new column to the trade table:\n",
    "\n",
    "Syntax:```addcol[dbdir;table;col;defaultvalue]```\n",
    " \n",
    "Let's add a new column called `newCol1` of type `symbol` to the trade table. Then add a second new column called `newCol2` of type `float` to the trade table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.02/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.03/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.06/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.07/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.08/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.09/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.10/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.13/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.14/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.15/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.16/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.17/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.20/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.21/tradeColumn addition successful!\n",
      "\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.22/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.23/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.24/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.27/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.28/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.29/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.30/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2020.01.31/trade\n",
      "2025.03.07 03:08:42 adding column newCol1 (type -20) to `:./2025.03.07/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.02/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.03/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.06/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.07/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.08/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.09/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.10/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.13/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.14/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.15/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.16/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.17/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.20/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.21/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.22/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.23/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.24/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.27/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.28/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.29/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.30/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2020.01.31/trade\n",
      "2025.03.07 03:08:42 adding column newCol2 (type -9) to `:./2025.03.07/trade\n"
     ]
    }
   ],
   "source": [
    "addcol[`:.;`trade;`newCol1;`]\n",
    "addcol[`:.;`trade;`newCol2;0f]\n",
    "system \"l .\"\n",
    "\"Column addition \",?[all `newCol1`newCol2 in cols select from trade where date=last date;\"successful!\";\"failure!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i>Always remember to run system \"l .\" after making runnning dbmaint functions to make sure your process has picked up the new changes. </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Syntax:```deletecol[dbdir;table;col]```\n",
    "\n",
    "Let's delete the previously created columns `newCol1` and `newCol2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.02/trade\n",
      "Column deletion successful!\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.03/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.06/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.07/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.08/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.09/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.10/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.13/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.14/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.15/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.16/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.17/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.20/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.21/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.22/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.23/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.24/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.27/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.28/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.29/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.30/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2020.01.31/trade\n",
      "2025.03.07 03:14:22 deleting column newCol1 from `:./2025.03.07/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.02/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.03/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.06/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.07/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.08/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.09/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.10/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.13/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.14/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.15/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.16/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.17/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.20/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.21/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.22/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.23/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.24/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.27/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.28/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.29/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.30/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2020.01.31/trade\n",
      "2025.03.07 03:14:22 deleting column newCol2 from `:./2025.03.07/trade\n"
     ]
    }
   ],
   "source": [
    "deletecol[`:.;`trade;`newCol1]\n",
    "deletecol[`:.;`trade;`newCol2]\n",
    "system \"l .\"\n",
    "\"Column deletion \",?[not all `newCol1`newCol2 in cols select from trade where date=last date;\"successful!\";\"failure!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i>The deleteCol function doesn't delete the col# files for nested columns (the files containing the actual values) – you will need to delete these manually.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "reveal": "angzbmv69t",
    "reveal-hidden": false
   },
   "source": [
    "##### Exercise \n",
    "\n",
    "Using a function in dbmaint, change the type of the size column to a short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "reveal": "angzbmv69t"
   },
   "outputs": [],
   "source": [
    "castcol[`:.;`trade;`size;`short]\n",
    "\\l .        //reloading database\n",
    "meta trade //checking if size column is now a short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "//your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Summary table of functions in dbmaint.q\n",
    "\n",
    "|Function |Purpose | Syntax|\n",
    "|---------|------|--------|\n",
    "|addcol |Adds new column col to table with value default value in each row|`addcol[dbdir;table;col;defaultvalue]`|\n",
    "|castcol|Cast the values in the column to the newtype and save.|`castcol[dbdir;table;col;newtype]`|\n",
    "|clearattrcol |Remove any attributes from column `col` |`clearattrcol[dbdir;table;col]`|\n",
    "|copycol|Copy the values from `oldcol` into a new column named `newcol`, undefined in the table.|`copycol[dbdir;table;oldcol;newcol]`|\n",
    "|deletecol| Delete column `col` from `table`|`deletecol[dbdir;table;col]`|\n",
    "|findcol|Print a list of the partition directories where `col` exists and its type in each|`findcol[dbdir;table;col]`|\n",
    "|fixtable|Adds missing columns to to all partitions of a table, given the location of a good partition.|`fixtable[dbdir;table;goodpartition]`|`fixtable[dbdir;table;goodpartition]`|\n",
    "|fncol|Apply a function to the list of values in `col` and save the results as its values.|`fncol[dbdir;table;col;fn]`|\n",
    "|listcols|List the columns of `table` (relies on the first partition)|`listcols[dbdir;table]`|\n",
    "|renamecol|Rename column `oldname` to `newname`, which must be undefined in the table|`renamecol[dbdir;table;oldname;newname]`|\n",
    "|reordercols|Reorder the columns of `table`. `neworder` is a full list of the column names as they appear in the updated table.| `reordercols[dbdir;table;neworder]`|\n",
    "|setattrcol|Apply an attribute to `col`. The data in the column must be valid for that attribute.|`setattrcol[dbdir;table;col;newattr]`|`setattrcol[dbdir;table;col;newattr]`|\n",
    "|addtable|Add a table called `tablename` with an empty table with the same schema as `table` created in each partition of the new table.|`addtable[dbdir;tablename;table]`|\n",
    "|rentable|Rename table `old` to `new`|`rentable[dbdir;old;new]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Further resources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make sure to check out *Partitioned Databases - Tips and Tricks* notebook to find out more about:\n",
    "* Virtual columns\n",
    "* Sorting large partitions \n",
    "* Database compression \n",
    "* Database modification  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
