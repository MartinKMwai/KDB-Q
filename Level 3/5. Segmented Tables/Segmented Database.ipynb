{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autorun": true,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#;.pykx.disableJupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autorun": true,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyKX now running in 'jupyter_qfirst' mode. All cells by default will be run as q code. \n",
      "Include '%%py' at the beginning of each cell to run as python code. \n"
     ]
    }
   ],
   "source": [
    "# https://code.kx.com/pykx/3.0/examples/jupyter-integration.html#q-first-mode\n",
    "import pykx as kx\n",
    "kx.util.jupyter_qfirst_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating local segmented database in :/home/jovyan/course-advanced/.hidden/db/segmentedDBRoot for use within the current section.\n",
      "Finished segmented database creation.\n"
     ]
    }
   ],
   "source": [
    "system\"l init.q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Outcomes**\n",
    "\n",
    "To understand: \n",
    "* Why use a segmented database?\n",
    "* The structure of a segmented database\n",
    "* How to use par.txt\n",
    "* Saving data to segments\n",
    "* Creating a segmented database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "For large time-series databases, kdb+ introduced segmentation. This involves storing data partitions in multiple locations outside of the root directory. These locations are known as segments. This is an extension of the partitioned database we discussed previously - in fact each segment of the database will have some number of the data partitions.\n",
    "\n",
    "With this structure, kdb+ can access and retrieve large amounts of data across segments in parallel. Let's first look at the structure of the database below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"../images/SegmentedDisk0.png\" alt=\"Drawing\" style=\"width: 230px;\"/> </td>\n",
    "<td> <img src=\"../images/SegmentedDisk1.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"../images/SegmentedDisk2.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Why segment a database? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are three main reasons why databases are segmented: \n",
    "\n",
    "1. For **Storage Capacity** Reasons: When dealing with databases on the order of Petabytes it is by necessity that databases need to be split across many different storage devices as it cannot all be fit on one. \n",
    "2. For **Performance** Reasons: When data is being retrieved from a given disk the read and write performance is limited by the I/O capacity of the disk itself (see [IOPS](https://en.wikipedia.org/wiki/IOPS)). By distributing intensive queries across multiple disks, the overhead due to I/O can be significantly reduced. \n",
    "3. For **Cost** Purposes: In many cases data has a recency bias in term of how often it is accessed - newer data is accessed frequently, while older data is accessed far less so. This means in many cases high performances (costly) disks are used for the recent data (in Finance for example the last 3-6 months of data), while older less accessed data is offloaded onto cheaper storage (.e.g hard spinning disks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Differences between Partitioned and Segmented databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "|  | Partitioned Table | Segmented Table |\n",
    "| --- | --- | --- |\n",
    "| Record location |\tAll partitions (and hence all records) reside under the root directory. | None of the segments (and hence no records) reside under the root. |\n",
    "| I/O channels | All partitions (and hence all records) reside on a single I/O channel. | The segments (and hence the records) should reside on multiple I/O channels. |\n",
    "| Processing | Partitions loaded and processed sequentially in aggregation queries.\t | Given appropriate slaves and cores, aggregate queries load segments in parallel and process them concurrently. |\n",
    "| Symbols | Cannot partition on a symbol column. | Can segment along a symbol column |\n",
    "| Virtual Column | Partition column not stored. Virtual column values inferred from directory names | No special column associated with segmentation (virtual column from underlying partition still present) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Segmented Database Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Segmented Database Home \n",
    "The only items that will remain in the root directory are the sym file the par.txt file and any flat or splayed reference tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The **par.txt** file exists so that q can read it in order to determine the location of each segment. Each line in the **par.txt** file will point to a specific segment. The local Segmented database has been created in the `segmentedDBRoot` directory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`daily`depth`mas`par.txt`sym\n"
     ]
    }
   ],
   "source": [
    "key `:segmentedDBRoot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see a number of files in this directory - our familiar `sym` file, and three flat tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       sym  open  high  low   close price   size \n",
      "-----------------------------------------------------\n",
      "2020.01.02 AAPL 83.9  86.52 82.87 86.22 4480705 52948\n",
      "2020.01.02 AIG  26.99 29.07 26.69 29    1508183 53858\n",
      "2020.01.02 AMD  33.01 34    32.89 33.93 1794876 53829\n",
      "date       time         sym  price size side ex\n",
      "-----------------------------------------------\n",
      "2020.01.31 09:30:01.068 TXN  19.74 100  S    O \n",
      "2020.01.31 09:30:20.507 INTC 53.09 400  B    N \n",
      "2020.01.31 09:30:41.953 INTC 53.3  300  B    N \n",
      "sym  name                     \n",
      "------------------------------\n",
      "AMD  \"ADVANCED MICRO DEVICES\" \n",
      "AIG  \"AMERICAN INTL GROUP INC\"\n",
      "AAPL \"APPLE INC COM STK\"      \n"
     ]
    }
   ],
   "source": [
    "3 sublist get `:segmentedDBRoot/daily  //note we don't have our `sym file in memory yet as we haven't loaded the db\n",
    "3 sublist get `:segmentedDBRoot/depth       //hence why the symbol values are currently showing as integers\n",
    "3 sublist get `:segmentedDBRoot/mas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The new file that is specific to the segmented database structure is the `par.txt` file. It is this file that the kdb+/q process looks for in order to determine if the database is in fact segmented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Database Segments - The par.txt file\n",
    "\n",
    "Looking at our local segmented database, the `par.txt` exists in our Segmented database root. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3\"\n"
     ]
    }
   ],
   "source": [
    "read0 `:segmentedDBRoot/par.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These four file paths indicate the four different locations where the data in our segmented database is stored. In this instance the four locations are local and on the same disk, though in practical usage these are usually different disk mounts. \n",
    "\n",
    "Let's look at the corresponding data in these locations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0| `s#`2020.01.08`2020.01.16`2020.01.20`2020.01.24`2020.01.28\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1| `s#`2020.01.09`2020.01.13`2020.01.17`2020.01.21`2020.01.29\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2| `s#`2020.01.02`2020.01.06`2020.01.10`2020.01.14`2020.01.22`2020.01.30\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3| `s#`2020.01.03`2020.01.07`2020.01.15`2020.01.23`2020.01.27`2020.01.31\n"
     ]
    }
   ],
   "source": [
    "show segmentDict:segments!key each segments:hsym `$ read0 `:segmentedDBRoot/par.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "sum count each  segmentDict  //how many dates do we have in our database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can see that each of the segments contains a number of dates within our database and can build the full file path for each of our partitions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "//the below pairs each mount dir with the each date partion, on a pairwise basis then creates the full path\n",
    "show segPaths:` sv/: raze key[segmentDict](,/:)'value[segmentDict] \n",
    "show path:first 1?segPaths    //choose a random path \n",
    "key path                      //what's in this directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now see that our date partitions contain the TAQ data we have worked with before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Loading a Segmented Database \n",
    "\n",
    "Loading a segmented database is relatively straightforward and just involves loading the root segment directory with the par.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For example, lets load our pre-created local segmented database we have been inspecting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\\l segmentedDBRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`daily`depth`mas`nbbo`quote`td`trade\n"
     ]
    }
   ],
   "source": [
    "tables[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After loading this directory, we have in memory the flat tables within our root directory, and our usual `sym` and `date` variables we know from working with partitioned databases: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`daily`depth`mas`par.txt`sym\n"
     ]
    }
   ],
   "source": [
    "key `:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`AAPL`AIG`AMD`DELL`DOW`GOOG`HPQ`IBM`INTC`MSFT`ORCL`PEP`PRU`SBUX`TXN\n",
      "2020.01.02 2020.01.03 2020.01.06 2020.01.07 2020.01.08 2020.01.09 2020.01.10 2020.01.13 2020.01.14 2020.01.15 2020.01.16 2020.01.17 2020.01.20 2020.01.21 2020.01.22 2020.01.23 2020.01.24 2020.01.27..\n"
     ]
    }
   ],
   "source": [
    "sym \n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `trade`, `quote` and `nbbo` tables are reconstructed from the partitions in each of our segments, however this is abstracted from us as users and we can continue to query our tables as we have previously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      | x    \n",
      "----------| -----\n",
      "2020.01.02| 14754\n",
      "2020.01.03| 15087\n",
      "2020.01.06| 14687\n",
      "2020.01.07| 14049\n",
      "2020.01.08| 14436\n",
      "2020.01.09| 13939\n",
      "2020.01.10| 13579\n",
      "2020.01.13| 14684\n",
      "2020.01.14| 14560\n",
      "2020.01.15| 14739\n",
      "2020.01.16| 15082\n",
      "2020.01.17| 14984\n",
      "2020.01.20| 14556\n",
      "2020.01.21| 14445\n",
      "2020.01.22| 14583\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "select count i by date from trade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date       sym | open  high  low   close\n",
      "---------------| -----------------------\n",
      "2020.01.02 AAPL| 83.9  86.52 82.87 86.22\n",
      "2020.01.02 AIG | 26.99 29.07 26.69 29   \n",
      "2020.01.02 AMD | 33.01 34    32.89 33.93\n",
      "2020.01.02 DELL| 12    12.22 11.82 12.07\n",
      "2020.01.02 DOW | 20    20.63 19.82 20.44\n",
      "2020.01.02 GOOG| 72.02 72.54 70.2  71.04\n",
      "2020.01.02 HPQ | 35.98 36.04 33.93 34.57\n",
      "2020.01.02 IBM | 42    42.2  40.75 41.43\n",
      "2020.01.02 INTC| 51.04 51.07 48.22 49.44\n",
      "2020.01.02 MSFT| 29    29.24 28.04 28.74\n",
      "2020.01.02 ORCL| 35    35.53 34.62 34.82\n",
      "2020.01.02 PEP | 21.99 22.46 21.67 22.44\n",
      "2020.01.02 PRU | 58.95 61.2  58.81 59.66\n",
      "2020.01.02 SBUX| 63    63.19 61.93 63.04\n",
      "2020.01.02 TXN | 18    18.37 17.74 18.07\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "select open: first price, high:max price, low: min price, close: last price \n",
    "    by date, sym\n",
    "    from trade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Segmented Database Utilies \n",
    "\n",
    "There are some [`.Q` namespace](https://code.kx.com/q/ref/dotq/) utilities and variables which are useful when working with segmented databases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## `.Q.P` and `.Q.D`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In segmented databases:\n",
    "* [`.Q.P`](https://code.kx.com/q/ref/dotq/#qp-segments) returns a list of the segments (i.e. the contents of par.txt).\n",
    "* [`.Q.D`](https://code.kx.com/q/ref/dotq/#qd-partitions) contains a list of the partitions – conformant to `.Q.P` – that are present in each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2`:/home/jov..\n",
      "2020.01.08 2020.01.16 2020.01.20 2020.01.24 2020.01.28\n",
      "2020.01.09 2020.01.13 2020.01.17 2020.01.21 2020.01.29\n",
      "2020.01.02 2020.01.06 2020.01.10 2020.01.14 2020.01.22 2020.01.30\n",
      "2020.01.03 2020.01.07 2020.01.15 2020.01.23 2020.01.27 2020.01.31\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0| 2020.01.08 2020.01.16 2020.01.20 2020.01.24 2020.01.28\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1| 2020.01.09 2020.01.13 2020.01.17 2020.01.21 2020.01.29\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2| 2020.01.02 2020.01.06 2020.01.10 2020.01.14 2020.01.22 2020.01.30\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3| 2020.01.03 2020.01.07 2020.01.15 2020.01.23 2020.01.27 2020.01.31\n"
     ]
    }
   ],
   "source": [
    ".Q.P       //the path to each of our mounts\n",
    ".Q.D       //all the partitions (in our case dates) in the database\n",
    ".Q.P!.Q.D  //we can recreate our segment dictionary from earlier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And we can build all our segment paths making use of `.Q.P` and `.Q.D`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0/2020.01.08`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0/2020.01.16`:/home/jovyan/course-advanced/.hidden/db/segmented..\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "` sv' raze .Q.P(,/:)'`$string .Q.D  \n",
    "count ` sv' raze .Q.P(,/:)'`$string .Q.D  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `.Q.par`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The most commonly utilized function when working with segmented databases is [`.Q.par`](https://code.kx.com/q/ref/dotq/#qpar-locate-partition). This is a special in-built function that will return the full path location of a table and can be helpful when working with large HDBs.\n",
    "\n",
    "It uses the syntax `.Q.par[directory as a file path;part as a date;table]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2/2020.01.02/trade\n"
     ]
    }
   ],
   "source": [
    ".Q.par[`:.;2020.01.02;`trade]     //full path to this table on that date, given the database in this current directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sym  time         price size stop cond ex\n",
      "-----------------------------------------\n",
      "AAPL 09:30:00.434 83.9  13   0    C    N \n",
      "AAPL 09:30:00.785 83.8  65   0    Z    N \n",
      "AAPL 09:30:01.273 83.76 75   0    Z    N \n",
      "AAPL 09:30:05.311 83.69 35   0    W    N \n",
      "AAPL 09:30:05.760 83.66 61   0    K    N \n",
      "AAPL 09:30:07.334 83.73 97   0    9    N \n",
      "AAPL 09:30:11.544 83.7  71   0    E    N \n",
      "AAPL 09:30:11.976 83.62 27   0    W    N \n",
      "AAPL 09:30:12.435 83.6  78   0    G    N \n",
      "AAPL 09:30:13.205 83.53 49   0    W    N \n",
      "AAPL 09:30:13.875 83.47 92   0    Z    N \n",
      "AAPL 09:30:14.789 83.52 14   0    B    N \n",
      "AAPL 09:30:17.346 83.54 62   0    J    N \n",
      "AAPL 09:30:18.556 83.65 35   0    L    N \n",
      "AAPL 09:30:24.985 83.7  86   0    A    N \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "get .Q.par[`:.;2020.01.02;`trade] // running get just displays the table at that location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:12px;padding-left:5px;\" align=\"left\"/>\n",
    "<p style='color:#273a6e'><i> <code>.Q.par</code> builds the path acting on the assumption that the partitions are distributed in a modulo fashion (explained in Section 4) depending on the date .e.g <code>2020.01.02 mod 4</code> is 2, therefore this date is determined to be in the 2nd mount as per par.txt. </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## `.Q.PV` and `.Q.PD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If the database is not structured in modulo fashion, we can't rely on using .Q.par to can build our own file paths. In this case we rely on [`.Q.PV`](https://code.kx.com/q/ref/dotq/#qpv-modified-partition-values) and [`.Q.PD`](https://code.kx.com/q/ref/dotq/#qpd-partition-locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`.Q.PD` contains a list of partition locations – conformant to .Q.PV – which represents the partition location for each partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`.Q.PV` returns a list of partition values – conformant to .Q.PD – which represents the partition value for each partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`.Q.PV!.Q.PD` can be used to create a dictionary of partition-to-location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3`:/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2`:/home/jov..\n",
      "2020.01.02 2020.01.03 2020.01.06 2020.01.07 2020.01.08 2020.01.09 2020.01.10 2020.01.13 2020.01.14 2020.01.15 2020.01.16 2020.01.17 2020.01.20 2020.01.21 2020.01.22 2020.01.23 2020.01.24 2020.01.27..\n",
      "2020.01.02| :/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2\n",
      "2020.01.03| :/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3\n",
      "2020.01.06| :/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2\n"
     ]
    }
   ],
   "source": [
    ".Q.PD                   // list of partition locations\n",
    ".Q.PV                   // list of partition values\n",
    "3 sublist .Q.PV!.Q.PD   // partition-to-location information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "reveal": "y75az61fckd",
    "reveal-hidden": false
   },
   "source": [
    "##### Exercise\n",
    "\n",
    "Create a function called `getPath` using `.Q.PD` and `.Q.PV`. This function will take two inputs, the date and the tablename and return the full filepath to that table - don't use `.Q.par`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "reveal": "y75az61fckd"
   },
   "outputs": [],
   "source": [
    "3 sublist .Q.PV!.Q.PD    //date to mount dictionary \n",
    "getPath:{[dt;tabname] mnt:(.Q.PV!.Q.PD)[dt]; \n",
    "                ` sv mnt,$[`;string dt],tabname}\n",
    "getPath[2020.01.02;`trade]\n",
    "get getPath[2020.01.02;`trade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "//your answer here \n",
    "getPath:{[dt;tabname] mnt:(.Q.PV!.Q.PD)[dt]; \n",
    "                ` sv mnt,$[`;string dt],tabname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Saving data to segments \n",
    "\n",
    "In order to get the most benefit from the database segmentation, data should be distributed evenly across all mounts, and consideration should be taken to common query patterns. For our segmented database we have four segments named `d0`,`d1`,`d2` and `d3` respectively, as a reminder here is our par.txt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3\"\n"
     ]
    }
   ],
   "source": [
    "read0 `par.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If we have four date partitions and we want to store them in these segments, utilising the common round-robin method would mean they are stored as follows\n",
    "\n",
    "2016.01.01 ---- segmentedDBmounts/d0\n",
    "\n",
    "2016.01.02 ---- segmentedDBmounts/d1\n",
    "\n",
    "2016.01.03 ---- segmentedDBmounts/d2\n",
    "\n",
    "2016.01.04 ---- segmentedDBmounts/d3 \n",
    "\n",
    "The most common way to do this is to use the mod function in conjunction with the partition itself - e.g. `2016.01.01 mod 4` returns `0`, so we allocate to our first mount and so on.\n",
    "\n",
    "Consider the first partition above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0i\n"
     ]
    }
   ],
   "source": [
    "2016.01.01 mod 4    //since we have four mounts - therefore allocated to d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can abstract this more generally: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d0\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d2\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d3\"\n"
     ]
    }
   ],
   "source": [
    "d:2016.01.01;           //the partition for this date needs to go in the first segment\n",
    "show r:read0`:par.txt   //r is a list of our mounts\n",
    "count r                 //how many mounts do we have? \n",
    "r d mod count r         //getting the modulo versus the mount count - then indexing to get the corresponding mount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:2px;padding-left:5px;\" align=\"left\"/>\n",
    "<p style='color:#273a6e'><i> A date is just an integer in q representing the number of days since 2000.01.01 so we can use modulo with them.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It should be noted that the names of the segments are unimportant. The `mod` function uses the date & the `count` of the number of lines in the par.txt file as its two arguments. The result from this is then used to index back into the result from `read0` and extract the correct segment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "reveal": "usbg8pq3g7",
    "reveal-hidden": false
   },
   "source": [
    "##### Exercise \n",
    "\n",
    "Create a utility function - `savePath` - that takes a date and tablename and returns the save path for the new date. This should allocate using modulo on the date and round robin between the mounts. \n",
    "\n",
    "Assume that the par.txt file is in the current directory. \n",
    "\n",
    "Verify that this returns the same result as `.Q.par`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "reveal": "usbg8pq3g7"
   },
   "outputs": [],
   "source": [
    "savePath:{[dt;tabName] \n",
    "               mounts:read0 `:par.txt; \n",
    "               numMounts:count mounts;\n",
    "               allocateTo:mounts dt mod numMounts; //determine allocation\n",
    "               ` sv hsym[`$allocateTo],(`$string dt),tabName\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "reveal": "usbg8pq3g7"
   },
   "outputs": [],
   "source": [
    "savePath[2020.01.01;`tab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "reveal": "usbg8pq3g7"
   },
   "outputs": [],
   "source": [
    ".Q.par[`:.;2020.01.01;`tab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1/2020.01.01/tab\n",
      ":/home/jovyan/course-advanced/.hidden/db/segmentedDBmounts/d1/2020.01.01/tab\n"
     ]
    }
   ],
   "source": [
    "//your answer here \n",
    "savePath:{[dt;tabName] \n",
    "               mounts:read0 `:par.txt; \n",
    "               numMounts:count mounts;\n",
    "               allocateTo:mounts dt mod numMounts; //determine allocation\n",
    "               ` sv hsym[`$allocateTo],(`$string dt),tabName\n",
    " }\n",
    "\n",
    "savePath[2020.01.01;`tab]\n",
    "\n",
    ".Q.par[`:.;2020.01.01;`tab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating Segmented Tables\n",
    "\n",
    "There is no one-size-fits-all utility to create segments. Instead, you write a q program that places a subset of each partition slice into a segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets now try and create our own segmented databases.\n",
    "\n",
    "We will use directories `...06 Segmented Databases/1`, `...06 Segmented Databases/2` and `...06 Segmented Databases/seg_root` as our segmented database root, when we construct the segments and write our **par.txt** file.\n",
    "\n",
    "First let's navigate back to our module home directory (`...06 Segmented Databases`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\\cd ../               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:/home/jovyan/course-advanced/.hidden/db\n",
      "/home/jovyan/course-advanced/.hidden/db\n"
     ]
    }
   ],
   "source": [
    "show dir: hsym `$d:first system\"pwd\"\n",
    "d   //module root string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's build our segmented database root director: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`:/home/jovyan/course-advanced/.hidden/db/seg_root\n"
     ]
    }
   ],
   "source": [
    "show segRoot:` sv  dir,`seg_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Firstly we'll put some data in each of our \"mounts\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/jovyan/course-advanced/.hidden/db/1/2021.01.02/seg/\n",
      ":/home/jovyan/course-advanced/.hidden/db/2/2021.01.03/seg/\n",
      ":/home/jovyan/course-advanced/.hidden/db/1/2021.01.04/seg/\n",
      ":/home/jovyan/course-advanced/.hidden/db/2/2021.01.05/seg/\n"
     ]
    }
   ],
   "source": [
    "(` sv (dir,`$\"1/2021.01.02/seg/\")) set .Q.en[segRoot;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:101 17f)\n",
    "(` sv (dir,`$\"2/2021.01.03/seg/\")) set .Q.en[segRoot;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:101.5 17.5)\n",
    "(` sv (dir,`$\"1/2021.01.04/seg/\")) set .Q.en[segRoot;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:103 16.5f)\n",
    "(` sv (dir,`$\"2/2021.01.05/seg/\")) set .Q.en[segRoot;] ([] ti:09:30:00 09:31:00; s:`ibm`t; p:102 17f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And update our par.txt file to have the paths to each of our data mounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/jovyan/course-advanced/.hidden/db/seg_root/par.txt\n",
      "\"/home/jovyan/course-advanced/.hidden/db/1\"\n",
      "\"/home/jovyan/course-advanced/.hidden/db/2\"\n"
     ]
    }
   ],
   "source": [
    "(` sv (segRoot,`par.txt)) 0: (d,\"/1\"; d,\"/2\")   //paths are relative to ./db_exc dir\n",
    "read0 ` sv (segRoot,`par.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've now made our segmented database! \n",
    "\n",
    "Let's take a second to make sure everything is in order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021.01.02 2021.01.04\n",
      "2021.01.03 2021.01.05\n",
      "`:/home/jovyan/course-advanced/.hidden/db/1`:/home/jovyan/course-advanced/.hidden/db/2\n"
     ]
    }
   ],
   "source": [
    "show mounts: hsym `$read0 ` sv (segRoot,`par.txt)  //this list of each of our \"mounts\" for our segmented database\n",
    "key each mounts                                    //the partitions exist for each of our mounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`s#`par.txt`sym\n"
     ]
    }
   ],
   "source": [
    "key segRoot          //our home directory has our par.txt and sym file - all looks good! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our final test is now to load the directory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/course-advanced/.hidden/db/seg_root\n",
      "\"/home/jovyan/course-advanced/.hidden/db/seg_root\"\n"
     ]
    }
   ],
   "source": [
    "1_ string segRoot                 //the directory path - dropping the : at the beginning\n",
    "system\"cd \",1_ string segRoot     //moving to the directory \n",
    "\\pwd                              //confirming correct\n",
    "\\l .                              //loading dir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once you load a directory (using `\\l dir`) you will automatically move into that directory - we can now see what tables we have in our directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`daily`depth`mas`nbbo`quote`seg`td`trade\n",
      "date       ti       s   p    \n",
      "-----------------------------\n",
      "2021.01.02 09:30:00 ibm 101  \n",
      "2021.01.02 09:31:00 t   17   \n",
      "2021.01.03 09:30:00 ibm 101.5\n",
      "2021.01.03 09:31:00 t   17.5 \n",
      "2021.01.04 09:30:00 ibm 103  \n"
     ]
    }
   ],
   "source": [
    "tables[]\n",
    "5#select from seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"../images/qbies.png\" style=\"width: 50px;padding-right:5px;padding-top:12px;padding-left:5px;\" align=\"left\"/>\n",
    "\n",
    "<p style='color:#273a6e'><i>Remember to ensure the segments conform and are complete. Overlapping segments will result in duplicate records in query results and an incomplete decomposition will result in dropped records!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Quiz Time!\n",
    "Try the Segmented Exercises to try writing a segmented database yourself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
